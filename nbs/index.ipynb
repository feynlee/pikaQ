{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pikaQ\n",
    "\n",
    "> Programmatically generate SQL queries for different dialects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library is heavily inspired by [PyPika](https://github.com/kayak/pypika), so a lot of the syntax is based on how PyPika works. \n",
    "Just like PyPika, PikaQ replaces handwritten SQL queries with programmatic construction of queries. \n",
    "The main difference is that pikaQ is designed to generate different SQL dialects from the same code. \n",
    "This is done by using a common syntax that is then translated to the specific dialect.\n",
    "\n",
    "This library provides the core components and implementation for constructing the `Select` query and the core mechanism for translating it into different dialect.\n",
    "It does not offer complete coverage of SQL syntax nor the detailed implementation of all the dialects.\n",
    "However, it should be easy to extend the library to support more SQL syntax and other types of queries you want to construct.\n",
    "\n",
    "Validation of SQL correctness is not an explicit goal of PikaQ. \n",
    "You are encouraged to check inputs you provide to PyPika or appropriately handle errors raised from your SQL database - just as you would have if you were writing SQL yourself."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install pikaQ\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed Translation\n",
    "\n",
    "The translation of the query is delayed until the `get_sql` method is called.\n",
    "All the components of the query have an `execute` method that returns the SQL string for that component, and when `get_sql` is called, the `execute` method of all the components are called recursively to generate the final SQL string.\n",
    "\n",
    "For example, if we want to write the same query in Spark SQL and AWS Athena, we might encounter this problem: we have `ADD_MONTHS` function in [Spark SQL](https://spark.apache.org/docs/2.3.0/api/sql/#add_months), but in AWS Athena ([Presto](https://prestodb.io/docs/current/functions/datetime.html#interval-functions)) we don't have this function.\n",
    "We can define an `ADD_MONTHS` function in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pikaQ.terms import custom_func\n",
    "from pikaQ.queries import Query\n",
    "\n",
    "\n",
    "@custom_func\n",
    "def add_months(column, value, dialect='spark'):\n",
    "    if dialect == 'athena':\n",
    "        return f\"DATE_ADD('month', {value}, {column})\"\n",
    "    elif dialect == 'spark':\n",
    "        return f'ADD_MONTH({column}, {value})'\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported dialect: {dialect}')\n",
    "\n",
    "\n",
    "q = (Query.from_('table')\n",
    "        .select('col1', add_months('col2', 3).as_('col2'))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can generate the query for Spark SQL and AWS Athena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select col1, DATE_ADD('month', 3, col2) AS col2\n",
      "from table\n"
     ]
    }
   ],
   "source": [
    "print(q.get_sql(dialect='athena'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select col1, ADD_MONTH(col2, 3) AS col2\n",
      "from table\n"
     ]
    }
   ],
   "source": [
    "print(q.get_sql(dialect='spark'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complex example to show how the syntax works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with s as (\n",
      "select distinct a.col1, a.col2, SUM(a.col3) OVER (PARTITION BY b.col2 ROWS BETWEEN 3 PRECEDING AND CURRENT_ROW) AS total, ROW_NUMBER() OVER (PARTITION BY b.col2 ORDER BY b.col4) AS row_num\n",
      "from tbl1 as a\n",
      "where col2 - 100 > 2 and col3 / 9 <= 1\n",
      "order by b.col2)\n",
      "\n",
      ", m as (\n",
      "select s.*\n",
      "from s\n",
      "where s.row_num = 1)\n",
      "\n",
      ", v as (\n",
      "select b.col1, b.col2, AVG(b.col3)\n",
      "from tbl2 as b\n",
      "group by b.col1, b.col2\n",
      "having COUNT(b.col3) > 2)\n",
      "\n",
      "select v.col1, v.col2, v.avg, CASE\n",
      "WHEN m.total > 100 THEN 1\n",
      "ELSE 0\n",
      "END AS flag\n",
      "from v\n",
      "join m on v.col1 = m.col1 and v.col2 = m.col2\n"
     ]
    }
   ],
   "source": [
    "from pikaQ.queries import Query, Table, Field, AliasedQuery\n",
    "from pikaQ.terms import Case, Preceding, CURRENT_ROW\n",
    "import pikaQ.functions as fn\n",
    "\n",
    "\n",
    "a = Table('tbl1').as_('a')\n",
    "b = Table('tbl2').as_('b')\n",
    "s = AliasedQuery('s')\n",
    "m = AliasedQuery('m')\n",
    "v = AliasedQuery('v')\n",
    "\n",
    "q0 = (Query\n",
    "      .from_(a)\n",
    "      .select(\n",
    "         a.col1,\n",
    "         a.col2,\n",
    "         fn.Sum(a.col3).over(b.col2).rows(Preceding(3), CURRENT_ROW).as_('total'), \n",
    "         fn.RowNumber().over(b.col2).orderby(b.col4).as_('row_num')\n",
    "      ).distinct()\n",
    "      .where((Field('col2')-100>2) & (Field('col3')/9<=1))\n",
    "      .orderby(b.col2)\n",
    ")\n",
    "q1 = (Query\n",
    "      .from_(b)\n",
    "      .select(b.col1, b.col2, fn.Avg(b.col3).as_('avg'))\n",
    "      .groupby(b.col1, b.col2)\n",
    "      .having(fn.Count(b.col3)>2)\n",
    ")\n",
    "\n",
    "q = (Query\n",
    "     .with_(q0, 's')\n",
    "     .with_(Query\n",
    "         .from_(s)\n",
    "         .select(s.star())\n",
    "         .where(s.row_num == 1), 'm')\n",
    "     .with_(q1, 'v')\n",
    "     .from_('v')\n",
    "     .join('m')\n",
    "        .on(\n",
    "            (v.col1 == m.col1) &\n",
    "            (v.col2 == m.col2)\n",
    "            )\n",
    "     .select(\n",
    "         v.col1, v.col2, v.avg,\n",
    "         Case().when(m.total>100, 1).else_(0).as_('flag')\n",
    "         )\n",
    ")\n",
    "\n",
    "print(q.get_sql())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more syntax examples, please refer to the [docs](https://feynlee.github.io/pikaQ/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension\n",
    "\n",
    "One can use the core components and logic implemented in this library to extend the functionality to support more SQL syntax and other types of queries.\n",
    "For details of how to extend the `SelectQuery` to support more clauses, please refer to the [Extending Query section](https://feynlee.github.io/pikaQ/queries.html#extending-query) of the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
