{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pikaQ\n",
    "\n",
    "> Programtically generate SQL queries for different dialects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library is heavily inspired by [pypika](https://github.com/kayak/pypika), so a lot of the syntax is based on how pypika works. \n",
    "Just like pypika, pikaQ replaces handwritten SQL queries with programmatic construction of queries.\n",
    "The main difference is that pikaQ is designed solve the problem of writing the same code that can be parsed to different SQL dialects. \n",
    "This is done by using a common syntax that is then translated to the specific dialect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install pikaQ\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to write the same query in SparkSQL and AWS Athena, we might encounter this problem: we have `ADD_MONTHS` function in SparkSQL, but in AWS Athena ([Presto](https://prestodb.io/docs/current/functions/datetime.html#interval-functions)) we don't have this function.\n",
    "\n",
    "We can define an `ADD_MONTHS` function in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select col1, DATE_ADD('month', 3, col2) AS col2\n",
      "from table\n",
      "select col1, ADD_MONTH(col2, 3) AS col2\n",
      "from table\n"
     ]
    }
   ],
   "source": [
    "from pikaQ.terms import custom_func\n",
    "from pikaQ.queries import Query\n",
    "\n",
    "\n",
    "@custom_func\n",
    "def add_months(column, value, dialect='spark'):\n",
    "    if dialect == 'athena':\n",
    "        return f\"DATE_ADD('month', {value}, {column})\"\n",
    "    elif dialect == 'spark':\n",
    "        return f'ADD_MONTH({column}, {value})'\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported dialect: {dialect}')\n",
    "\n",
    "\n",
    "q = (Query.from_('table')\n",
    "        .select('col1', add_months('col2', 3).as_('col2'))\n",
    ")\n",
    "\n",
    "print(q.get_sql(dialect='athena'))\n",
    "print(q.get_sql(dialect='spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with s as (\n",
      "select distinct a.col1, a.col2, SUM(a.col3) OVER (PARTITION BY b.col2 ROWS BETWEEN 3 PRECEDING AND CURRENT_ROW) AS total, ROW_NUMBER() OVER (PARTITION BY b.col2 ORDER BY b.col4) AS row_num\n",
      "from tbl1 as a\n",
      "where col2 - 100 > 2 and col3 / 9 <= 1\n",
      "order by b.col2)\n",
      "\n",
      ", m as (\n",
      "select s.*\n",
      "from s\n",
      "where s.row_num = 1)\n",
      "\n",
      ", v as (\n",
      "select b.col1, b.col2, AVG(b.col3)\n",
      "from tbl2 as b\n",
      "group by b.col1, b.col2\n",
      "having COUNT(b.col3) > 2)\n",
      "\n",
      "select v.col1, v.col2, v.avg, CASE\n",
      "WHEN m.total > 100 THEN 1\n",
      "ELSE 0\n",
      "END AS flag\n",
      "from v\n",
      "join m on v.col1 = m.col1 and v.col2 = m.col2\n"
     ]
    }
   ],
   "source": [
    "from pikaQ.queries import Query, Table, Field, AliasedQuery\n",
    "from pikaQ.terms import Case, Preceding, CURRENT_ROW\n",
    "import pikaQ.functions as fn\n",
    "\n",
    "\n",
    "a = Table('tbl1').as_('a')\n",
    "b = Table('tbl2').as_('b')\n",
    "s = AliasedQuery('s')\n",
    "m = AliasedQuery('m')\n",
    "v = AliasedQuery('v')\n",
    "\n",
    "q0 = (Query\n",
    "      .from_(a)\n",
    "      .select(\n",
    "         a.col1,\n",
    "         a.col2,\n",
    "         fn.Sum(a.col3).over(b.col2).rows(Preceding(3), CURRENT_ROW).as_('total'), \n",
    "         fn.RowNumber().over(b.col2).orderby(b.col4).as_('row_num')\n",
    "      ).distinct()\n",
    "      .where((Field('col2')-100>2) & (Field('col3')/9<=1))\n",
    "      .orderby(b.col2)\n",
    ")\n",
    "q1 = (Query\n",
    "      .from_(b)\n",
    "      .select(b.col1, b.col2, fn.Avg(b.col3).as_('avg'))\n",
    "      .groupby(b.col1, b.col2)\n",
    "      .having(fn.Count(b.col3)>2)\n",
    ")\n",
    "\n",
    "q = (Query\n",
    "     .with_(q0, 's')\n",
    "     .with_(Query\n",
    "         .from_(s)\n",
    "         .select(s.star())\n",
    "         .where(s.row_num == 1), 'm')\n",
    "     .with_(q1, 'v')\n",
    "     .from_('v')\n",
    "     .join('m')\n",
    "        .on(\n",
    "            (v.col1 == m.col1) &\n",
    "            (v.col2 == m.col2)\n",
    "            )\n",
    "     .select(\n",
    "         v.col1, v.col2, v.avg,\n",
    "         Case().when(m.total>100, 1).else_(0).as_('flag')\n",
    "         )\n",
    ")\n",
    "\n",
    "print(q.get_sql())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
